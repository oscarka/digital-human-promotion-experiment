# 火山引擎 API 模式说明

## 两种模式的区别

### 关键区别总结

**双向流式模式 (`bigmodel`)**：
- 音频流式发送 → **立即**流式返回识别结果
- 边发送边接收，实时看到结果

**流式输入模式 (`bigmodel_nostream`)**：
- 音频流式发送 → **等待完整音频后**返回最终结果
- 发送过程中不返回结果，最后一次性返回

---

### 1. 双向流式模式 (`bigmodel`)
**接口地址：** `wss://openspeech.bytedance.com/api/v3/sauc/bigmodel`

**特点：**
- ✅ **双向流式**：音频输入流式 + 识别结果流式返回
- ✅ **实时响应**：边发送音频边接收识别结果
- ✅ **低延迟**：适合实时对话场景
- ✅ **增量结果**：可以实时看到部分识别结果

**工作流程：**
```
客户端发送音频片段1 → 服务器立即返回部分识别结果1
客户端发送音频片段2 → 服务器立即返回部分识别结果2（可能包含片段1+2的结果）
客户端发送音频片段3 → 服务器立即返回部分识别结果3（可能包含片段1+2+3的结果）
...
```

**适用场景：**
- 实时语音识别（如语音输入法）
- 实时字幕生成
- 实时对话转录
- 需要立即看到识别结果的场景

---

### 2. 流式输入模式 (`bigmodel_nostream`)
**接口地址：** `wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_nostream`

**特点：**
- ✅ **流式输入**：音频可以分段流式发送
- ❌ **非流式输出**：等待完整音频发送完毕后，才返回最终识别结果
- ✅ **完整结果**：返回完整的、准确的识别结果
- ⚠️ **延迟较高**：需要等待所有音频发送完成

**工作流程：**
```
客户端发送音频片段1 → 服务器接收（不返回结果）
客户端发送音频片段2 → 服务器接收（不返回结果）
客户端发送音频片段3 → 服务器接收（不返回结果）
...
客户端发送最后一个片段（标记为结束） → 服务器返回完整识别结果
```

**适用场景：**
- 上传完整音频文件进行识别
- 需要完整、准确的识别结果
- 可以接受延迟的场景
- 批量音频处理

---

## 对比表格

| 特性 | 双向流式 (`bigmodel`) | 流式输入 (`bigmodel_nostream`) |
|------|---------------------|-------------------------------|
| **输入方式** | 流式发送 | 流式发送 |
| **输出方式** | 流式返回（实时） | 完整返回（等待结束） |
| **延迟** | 低（实时） | 较高（等待完整音频） |
| **结果格式** | 增量结果 | 完整结果 |
| **适用场景** | 实时对话、字幕 | 文件上传、批量处理 |
| **用户体验** | 实时看到结果 | 等待后看到完整结果 |

---

## 在你的项目中的应用

### 当前实现
你的项目当前使用 `bigmodel`（双向流式模式），这是**正确的选择**，因为：

1. ✅ **实时转录**：用户上传音频后，可以实时看到识别结果
2. ✅ **更好的体验**：不需要等待整个音频处理完成
3. ✅ **符合需求**：你的项目需要实时显示转录结果

### 如果改用 `bigmodel_nostream`
如果切换到 `bigmodel_nostream`：

**优点：**
- 结果更完整、更准确（等待完整音频后处理）

**缺点：**
- 用户需要等待整个音频发送完成才能看到结果
- 体验不如实时流式好
- 对于长音频，等待时间较长

---

## 代码中的配置

在你的代码中，`enable_nonstream` 参数控制是否使用非流式输出：

```python
"request": {
    "model_name": "bigmodel",
    "enable_nonstream": False  # False = 流式输出，True = 非流式输出
}
```

**注意：**
- `enable_nonstream: False` + `bigmodel` 端点 = 双向流式模式 ✅
- `enable_nonstream: True` + `bigmodel_nostream` 端点 = 流式输入模式 ✅

---

## 关于 Resource-Id

你修改了 `X-Api-Resource-Id` 从 `volc.bigasr.sauc.duration` 改为 `volc.seedasr.sauc.duration`。

这可能是因为：
- `volc.seedasr` - 对应"豆包流式语音识别模型2.0"（Seed ASR）
- `volc.bigasr` - 可能是其他版本的 ASR 服务

请根据你的实际服务类型使用正确的 Resource-Id。

---

## 建议

**对于你的项目，继续使用 `bigmodel`（双向流式模式）**，因为：

1. ✅ 用户体验更好（实时看到结果）
2. ✅ 符合"实时流识别"的需求
3. ✅ 延迟更低

只有在以下情况才考虑 `bigmodel_nostream`：
- 需要更准确的完整结果
- 可以接受等待时间
- 处理长音频文件

---

## 实际测试

你可以通过修改 `.env.local` 中的 `VOLCANO_API_URL` 来测试两种模式：

**双向流式模式（推荐）：**
```env
VOLCANO_API_URL=wss://openspeech.bytedance.com/api/v3/sauc/bigmodel
```

**流式输入模式：**
```env
VOLCANO_API_URL=wss://openspeech.bytedance.com/api/v3/sauc/bigmodel_nostream
```

然后重启代理服务器和前端应用，观察识别结果的返回方式差异。
