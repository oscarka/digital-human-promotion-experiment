# 电话医生服务商推流接入规划

## 📋 概述

电话医生服务商会在通话开始时向您提供的地址推流音频，通话结束后回调通知。需要将实时音频流接入到现有的语音识别和AI分析系统中。

---

## 🔧 需要配置的内容

### 1. **环境变量配置** (`.env.local`)

需要添加以下配置项：

```env
# 电话医生服务商配置
TELEPHONE_SERVICE_ENABLED=true
TELEPHONE_SERVICE_WEBHOOK_SECRET=your_webhook_secret_here  # 用于验证回调请求的密钥

# 推流接收地址（需要提供给服务商）
TELEPHONE_STREAM_RECEIVE_URL=https://your-domain.com/api/telephone/stream

# 回调接收地址（需要提供给服务商）
TELEPHONE_CALLBACK_URL=https://your-domain.com/api/telephone/callback

# 可选：服务商特定的配置
TELEPHONE_SERVICE_PROVIDER=provider_name  # 服务商名称
TELEPHONE_SERVICE_API_KEY=your_api_key    # 如果服务商需要API密钥
```

### 2. **后端API端点** (需要新建)

需要创建以下API端点来接收服务商的推流和回调：

#### 2.1 推流接收端点
- **路径**: `/api/telephone/stream` 或 `/api/telephone/stream/:call_id`
- **方法**: `POST` 或 `WebSocket` 或 `PUT`（取决于服务商协议）
- **功能**: 接收服务商推送的实时音频流
- **触发时机**: 服务商在医生接听电话时主动调用此地址
- **数据格式**: 需要确认服务商推流的格式（可能是 WebSocket、HTTP 流、RTMP 等）
- **请求头**: 可能包含 `call_id`、`doctor_id`、`patient_id` 等信息
- **处理流程**:
  1. 接收推流请求
  2. 验证请求合法性（签名、token等）
  3. 开始接收音频流数据
  4. 通过WebSocket通知前端客户端（弹出提示）
  5. 将音频流转发给语音识别服务

#### 2.2 回调接收端点
- **路径**: `/api/telephone/callback`
- **方法**: `POST`
- **功能**: 接收通话开始/结束的回调通知
- **请求体字段**:
  - event: 事件类型（call_started 或 call_ended）
  - call_id: 唯一通话ID
  - doctor_id: 医生ID（必须，用于关联医生账号）
  - patient_id: 患者ID
  - timestamp: 时间戳
  - stream_url: 推流地址（如果是通话开始）

### 3. **账号关联机制** (必需)

**核心问题**: 多个医生同时在线时，如何知道推流是给哪个医生的？

**解决方案**: 
- 服务商在推流请求和回调中必须携带 `doctor_id` 字段
- `doctor_id` 必须与电话系统的医生账号ID一致
- 客户端连接WebSocket时，需要携带当前登录医生的 `doctor_id`
- 后端根据 `doctor_id` 匹配对应的客户端连接，只通知对应的医生

**账号关联流程**:
1. 医生在客户端登录时，获取医生账号ID（来自电话系统或统一认证系统）
2. 客户端连接WebSocket时，发送 `doctor_id` 进行注册
3. 后端维护 `doctor_id` 到 WebSocket 连接的映射
4. 服务商推流时，在请求头或请求体中携带 `doctor_id`
5. 后端根据 `doctor_id` 找到对应的客户端连接，只通知该医生

**需要向服务商确认**:
- 推流请求中如何携带 `doctor_id`？（请求头、URL参数、请求体）
- `doctor_id` 的格式和来源（是否与电话系统账号ID一致）
- 回调通知中是否也包含 `doctor_id`

### 4. **数据库/存储** (可选，用于管理通话记录)

如果需要记录通话信息，可能需要：
- 通话记录表（call_id, doctor_id, patient_id, start_time, end_time, status）
- 音频流存储（如果服务商不提供回放）

---

## 🔄 业务流程设计

### 场景：医生在后台开启客户端，服务商主动推流

```
┌─────────────────────────────────────────────────────────────┐
│  步骤 1: 医生后台客户端（保持运行）                          │
│  - 客户端在后台运行，监听推流请求                            │
│  - 可以显示"等待通话中..."状态                                │
│  - 客户端已准备好接收服务商的推流                           │
└─────────────────────────────────────────────────────────────┘
                          │
                          │ 医生在电话系统接听电话
                          │ 服务商检测到接听
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  步骤 2: 服务商主动调用推流地址                              │
│  - 服务商调用您提供的推流地址                                │
│  - 开始向您的服务器推送实时音频流                            │
│  - 同时发送"call_started"回调（包含通话信息）               │
└─────────────────────────────────────────────────────────────┘
                          │
                          │ 后端收到推流请求和回调
                          │ 通过WebSocket通知前端
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  步骤 3: 客户端弹出确认提示（新增）                          │
│  ┌─────────────────────────────────────┐                    │
│  │  📞 检测到新的通话                    │                    │
│  │                                      │                    │
│  │  患者：张三                          │                    │
│  │  通话时间：10:00                     │                    │
│  │                                      │                    │
│  │  是否开始实时解析？                  │                    │
│  │                                      │                    │
│  │  [稍后处理]  [开始实时解析]          │                    │
│  └─────────────────────────────────────┘                    │
└─────────────────────────────────────────────────────────────┘
                          │
                          │ 医生点击"开始实时解析"
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  步骤 4: 进入实时识别页面（类似SimulationMode）               │
│  - 自动跳转到 activeStep = 2（新增步骤）                      │
│  - 显示实时转录（左侧）                                       │
│  - 显示AI分析结果（右侧）                                     │
│  - 实时接收服务商推送的音频流                                │
│  - 实时进行语音识别和AI分析                                  │
│  - 显示通话时长、患者信息等                                  │
└─────────────────────────────────────────────────────────────┘
                          │
                          │ 通话进行中...
                          │
                          │ 服务商持续推送音频流
                          │  ↓
                          │ 实时识别和分析
                          │
                          │ 通话结束
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  步骤 5: 收到"call_ended"回调                                │
│  - 服务商停止推送音频流                                      │
│  - 后端收到"call_ended"回调                                  │
│  - 停止接收音频流                                            │
│  - 触发最终分析（triggerDeepAnalysis）                       │
│  - 生成最终诊断、产品推荐、话术                              │
└─────────────────────────────────────────────────────────────┘
                          │
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  步骤 6: 自动跳转到结果展示页（activeStep = 3）              │
│  - 显示健康背景、解决方案、推荐话术                          │
│  - 显示通话摘要                                              │
│  - 医生可以确认并发送给患者                                  │
│  - 医生可以返回工作台，继续等待下一个通话                    │
└─────────────────────────────────────────────────────────────┘
```

### 关键改进点

1. **不需要医生主动操作接听**：电话已经在电话系统里接听了
2. **客户端作为后台服务**：持续运行，监听推流请求
3. **自动弹出提示**：收到推流后自动弹出，医生只需确认是否开始解析
4. **更符合实际场景**：医生可能同时在处理其他事情，不需要主动操作

---

## 🏗️ 技术架构

### 1. **前端改动**

#### 1.1 修改App.tsx为后台监听模式
- 客户端启动后保持运行状态
- 通过WebSocket连接到后端，监听推流通知
- 显示"等待通话中..."或"就绪"状态
- 可以最小化到系统托盘（可选）

#### 1.2 新增通话开始提示弹窗组件
- 当后端收到推流请求时，通过WebSocket通知前端
- 前端自动弹出此提示
- 显示信息：患者姓名、通话时间、通话ID等
- 操作选项：医生可以选择"开始实时解析"或"稍后处理"
- 账号验证：只显示属于当前登录医生的通话通知

#### 1.3 新增实时通话页面（类似SimulationMode，但接收外部音频流）
- 功能：接收服务商推送的音频流，实时进行语音识别和AI分析
- 参数：通话ID、音频流地址、语音识别服务提供商
- 显示：实时转录（左侧）、AI分析结果（右侧）
- 账号关联：确保只处理属于当前登录医生的通话

#### 1.4 修改App.tsx的步骤流程
- 当前：步骤1（上传）→ 步骤3（结果）
- 新增：步骤1（工作台）→ 步骤2（实时通话）→ 步骤3（结果）

### 2. **后端改动** (需要新建Node.js后端服务)

#### 2.1 推流接收服务
- 功能：接收服务商推送的音频流
- 实现方式：根据服务商协议选择（WebSocket服务器、HTTP流接收、RTMP服务器等）
- 账号验证：从推流请求中提取 `doctor_id`，验证是否为有效医生账号
- 路由转发：将音频流转发给语音识别服务（Gemini或火山引擎）

#### 2.2 回调接收服务
- 功能：接收服务商的回调通知（通话开始/结束）
- 处理流程：
  1. 验证回调签名（如果服务商提供）
  2. 提取 `doctor_id` 字段
  3. 根据 `doctor_id` 查找对应的WebSocket连接
  4. 只通知对应的医生客户端（不是广播给所有客户端）
  5. 如果是通话结束，停止接收音频流并触发最终分析

#### 2.3 WebSocket服务器（用于前后端通信）
- 功能：
  1. 前端客户端连接后保持长连接
  2. 客户端连接时，需要发送 `doctor_id` 进行注册
  3. 后端维护 `doctor_id` 到 WebSocket 连接的映射表
  4. 后端收到服务商回调后，根据 `doctor_id` 找到对应的连接，只通知该医生
  5. 后端收到推流请求后，同样根据 `doctor_id` 通知对应医生
  6. 前端可以发送控制命令（如"开始解析"、"停止解析"）

- 账号关联实现：
  - 使用 Map 数据结构存储：key = doctor_id, value = WebSocket连接
  - 客户端断开连接时，从映射表中移除
  - 通知时，只向对应的医生客户端发送消息，不广播

### 3. **音频流处理**

#### 3.1 接收服务商音频流
- 需要确认服务商推流的格式（WebSocket、HTTP流、RTMP等）
- 将接收到的音频流转发给语音识别服务（Gemini或火山引擎）

#### 3.2 音频格式转换
- 如果服务商推送的格式与识别服务要求不一致，需要转换
- 可能需要：采样率转换、格式转换（PCM、WAV等）

---

## 📝 需要向服务商确认的信息

### 1. **推流相关**
- [ ] 推流协议：WebSocket、HTTP流、RTMP、其他？
- [ ] 音频格式：PCM、WAV、MP3、其他？
- [ ] 采样率：16kHz、8kHz、其他？
- [ ] 声道：单声道、立体声？
- [ ] 推流地址格式：需要提供完整URL还是只需要路径？
- [ ] 认证方式：需要API Key、Token、还是其他？

### 2. **回调相关**
- [ ] 回调协议：HTTP POST、WebSocket、其他？
- [ ] 回调数据格式：JSON、XML、其他？
- [ ] 回调事件类型：call_started、call_ended、其他？
- [ ] 回调数据字段：call_id、doctor_id、patient_id等具体字段名
- [ ] 回调认证：是否需要签名验证？

### 3. **业务相关**
- [ ] 推流请求的触发时机：是医生接听电话时自动触发，还是需要额外操作？
- [ ] 通话ID的唯一性：如何确保call_id唯一？是否由服务商提供？
- [ ] 通话时长限制：是否有最大通话时长？
- [ ] 音频流延迟：推流延迟大概多少？
- [ ] **账号关联（重要）**：
  - [ ] 推流请求中如何携带 `doctor_id`？（请求头、URL参数、请求体）
  - [ ] `doctor_id` 的格式和来源（是否与电话系统账号ID一致）
  - [ ] 回调通知中是否也包含 `doctor_id`
  - [ ] `doctor_id` 是否与电话系统的医生账号ID完全一致
- [ ] 推流请求的认证：推流请求是否需要认证？如何验证是服务商发起的？

---

## 🎯 实施优先级

### Phase 1: 基础架构
1. ✅ 创建后端API端点框架
2. ✅ 配置环境变量
3. ✅ 创建WebSocket服务器（前后端通信）

### Phase 2: 推流接收
1. ✅ 实现推流接收服务（根据服务商协议）
2. ✅ 音频格式转换（如果需要）
3. ✅ 将音频流转发给语音识别服务

### Phase 3: 前端界面
1. ✅ 修改App.tsx为后台监听模式
2. ✅ 实现WebSocket客户端连接（保持长连接）
3. ✅ 创建通话开始提示弹窗组件
4. ✅ 创建实时通话页面（LiveCallMode）
5. ✅ 修改App.tsx步骤流程（1→2→3）

### Phase 4: 回调处理
1. ✅ 实现回调接收服务
2. ✅ 回调验证（签名验证等）
3. ✅ 回调通知前端（通过WebSocket）

### Phase 5: 测试和优化
1. ✅ 端到端测试
2. ✅ 性能优化
3. ✅ 错误处理

---

## 🔍 关键决策点

### 1. **推流接收方式**
- **选项A**: 使用WebSocket服务器直接接收（如果服务商用WebSocket推流）
- **选项B**: 使用HTTP流接收（如果服务商用HTTP推流）
- **选项C**: 使用RTMP服务器（如果服务商用RTMP推流）

**建议**: 先确认服务商的推流协议，再决定实现方式。

### 2. **前后端通信方式**
- **选项A**: WebSocket（实时性好，适合实时音频流）
- **选项B**: Server-Sent Events（单向，适合通知）
- **选项C**: HTTP轮询（简单但延迟高）

**建议**: 使用WebSocket，因为需要实时传输音频流。

### 3. **音频流存储**
- **选项A**: 不存储，只实时处理（节省存储空间）
- **选项B**: 存储原始音频流（可用于回放、分析）

**建议**: 先不存储，如果后续需要回放功能再添加。

---

## 📌 注意事项

1. **安全性**
   - 推流地址和回调地址需要HTTPS
   - 回调请求需要验证签名，防止伪造
   - API密钥需要安全存储

2. **可扩展性**
   - 考虑多医生同时接听的情况
   - 音频流处理需要支持并发

3. **错误处理**
   - 推流中断的处理
   - 回调失败的重试机制
   - 网络异常的处理

4. **性能**
   - 音频流处理的延迟
   - 实时识别的性能
   - 服务器资源占用

---

## 🚀 下一步行动

1. **与服务商确认推流和回调的具体协议和格式**
2. **根据确认的信息，选择合适的技术方案**
3. **创建详细的技术设计文档**
4. **开始实施Phase 1的基础架构**
