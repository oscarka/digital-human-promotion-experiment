# 测试指南

## 前置准备

### 1. 检查环境变量

确保 `.env.local` 文件包含正确的配置：

```env
# Google Gemini API（必需）
GEMINI_API_KEY=your_gemini_api_key

# 火山引擎 API（如果使用火山引擎）
VOLCANO_APP_KEY=your_volcano_app_key_here
VOLCANO_ACCESS_KEY=your_volcano_access_key_here
VOLCANO_API_URL=wss://openspeech.bytedance.com/api/v3/sauc/bigmodel
VOLCANO_PROXY_URL=ws://localhost:3001
VOLCANO_USE_PROXY=true
```

### 2. 安装依赖

```bash
npm install
```

## 测试步骤

### 步骤 1: 启动代理服务器（必需）

**新开一个终端窗口**，运行：

```bash
npm run proxy
```

或者：

```bash
node proxy-server.js
```

**预期输出：**
```
✅ 代理服务器已启动
📡 监听端口: 3001
🔗 火山引擎 API: wss://openspeech.bytedance.com/api/v3/sauc/bigmodel

前端应连接到: ws://localhost:3001
```

**如果看到错误：**
- 检查 `.env.local` 中的 `VOLCANO_APP_KEY` 和 `VOLCANO_ACCESS_KEY` 是否正确
- 确认端口 3001 没有被占用

---

### 步骤 2: 启动前端应用

**新开另一个终端窗口**，运行：

```bash
npm run dev
```

**预期输出：**
```
  VITE v6.x.x  ready in xxx ms

  ➜  Local:   http://localhost:5173/
  ➜  Network: use --host to expose
```

---

### 步骤 3: 打开浏览器测试

1. 打开浏览器访问 `http://localhost:5173/`
2. 在页面顶部选择 **"火山引擎豆包语音"**（而不是 "Google Gemini"）
3. 点击 **"开启实时流识别"** 按钮
4. 选择一个音频文件（WAV、MP3、M4A 等格式）

---

### 步骤 4: 验证修复效果

#### ✅ 测试点 1: 实时响应

**预期行为：**
- 上传音频后，**立即**开始显示识别结果
- 不需要等待所有音频发送完成
- 识别结果**实时更新**，边发送边显示

**如何验证：**
1. 上传一个较长的音频文件（> 10秒）
2. 观察识别结果是否在音频发送过程中就开始显示
3. 如果看到结果实时更新，说明修复成功 ✅

#### ✅ 测试点 2: 完整识别结果

**预期行为：**
- 所有音频段都正确发送
- 收到完整的识别结果
- 最后显示"识别完成"

**如何验证：**
1. 上传音频后，等待识别完成
2. 检查是否显示了完整的转录文本
3. 检查是否区分了"Doctor"和"Patient"角色（如果启用 DDC）

#### ✅ 测试点 3: 控制台日志

打开浏览器开发者工具（F12），查看 Console 标签：

**预期日志：**
```
Connecting to: ws://localhost:3001
WebSocket connected to proxy server
Sent audio segment 1/10 (seq: 1)
Sent audio segment 2/10 (seq: 2)
...
All audio segments sent
```

**如果看到这些日志，说明：**
- ✅ 连接成功
- ✅ 音频段正在发送
- ✅ 并发发送和接收正常工作

---

## 对比测试：修复前 vs 修复后

### 修复前（旧版本）

**行为：**
- ❌ 上传音频后，需要等待所有音频发送完成
- ❌ 然后才显示识别结果
- ❌ 用户体验差，感觉"卡顿"

**控制台日志：**
```
发送音频段 1...
发送音频段 2...
...
发送音频段 10...
等待响应...
收到响应...
```

### 修复后（新版本）

**行为：**
- ✅ 上传音频后，立即开始显示识别结果
- ✅ 边发送边显示，实时更新
- ✅ 用户体验好，流畅

**控制台日志：**
```
发送音频段 1...
收到响应 1... (实时显示)
发送音频段 2...
收到响应 2... (实时显示)
...
```

---

## 测试不同场景

### 场景 1: 短音频（< 5秒）

**测试步骤：**
1. 上传一个短音频文件
2. 观察识别结果是否快速显示

**预期：**
- 识别结果快速显示
- 完整结果一次性显示

### 场景 2: 长音频（> 30秒）

**测试步骤：**
1. 上传一个长音频文件
2. 观察识别结果是否实时显示

**预期：**
- 识别结果**实时显示**（关键测试点）
- 边发送边显示，不需要等待
- 最后显示完整结果

### 场景 3: 网络延迟

**测试步骤：**
1. 使用浏览器开发者工具的 Network 标签
2. 设置网络为 "Slow 3G"
3. 上传音频文件

**预期：**
- 即使网络慢，也能实时显示识别结果
- 不会因为网络慢而"卡住"

---

## 故障排查

### 问题 1: 连接失败

**症状：**
- 控制台显示 "Failed to connect to proxy server"

**解决方案：**
1. 确认代理服务器正在运行（步骤 1）
2. 检查 `VOLCANO_PROXY_URL` 是否为 `ws://localhost:3001`
3. 检查端口 3001 是否被占用

### 问题 2: 403 错误

**症状：**
- 代理服务器显示 "403 错误"

**解决方案：**
1. 检查 `.env.local` 中的 `VOLCANO_APP_KEY` 和 `VOLCANO_ACCESS_KEY`
2. 确认火山引擎服务已开通（控制台显示"已开通"）
3. 等待服务激活（5-10分钟）

### 问题 3: 没有实时响应

**症状：**
- 上传音频后，需要等待很久才显示结果

**可能原因：**
- 修复没有生效
- 检查代码是否正确更新

**验证方法：**
1. 查看控制台日志，确认是否看到 "Sent audio segment" 和响应交替出现
2. 如果看到所有 "Sent" 日志后才看到响应，说明修复未生效

### 问题 4: 识别结果不完整

**症状：**
- 只显示了部分识别结果

**解决方案：**
1. 检查是否收到了 `isLastPackage` 标志
2. 查看控制台是否有错误日志
3. 检查音频文件是否完整

---

## 使用 Python Demo 对比测试

如果想对比 Python demo 的行为，可以运行：

```bash
cd sauc_python

# 修改 sauc_websocket_demo.py 中的认证信息
# 然后运行：
python3 sauc_websocket_demo.py --file /path/to/your/audio.wav
```

**对比点：**
- Python demo 也是实时显示识别结果
- 修复后的 TypeScript 实现应该行为一致

---

## 成功标准

如果以下所有条件都满足，说明修复成功：

- ✅ 上传音频后，识别结果**立即开始显示**
- ✅ 识别结果**实时更新**，不需要等待所有音频发送完成
- ✅ 控制台日志显示发送和接收**交替进行**
- ✅ 最后显示**完整的识别结果**
- ✅ 用户体验流畅，没有"卡顿"感

---

## 快速测试命令

```bash
# 终端 1: 启动代理服务器
npm run proxy

# 终端 2: 启动前端应用
npm run dev

# 浏览器: 访问 http://localhost:5173/
# 选择"火山引擎豆包语音"，上传音频文件测试
```

---

## 测试检查清单

- [ ] 代理服务器成功启动
- [ ] 前端应用成功启动
- [ ] 浏览器能正常访问应用
- [ ] 选择"火山引擎豆包语音"选项
- [ ] 上传音频文件
- [ ] 识别结果实时显示（关键）
- [ ] 控制台日志显示并发发送和接收
- [ ] 最后显示完整识别结果
- [ ] 没有错误或警告

如果所有项目都打勾 ✅，说明测试通过！
